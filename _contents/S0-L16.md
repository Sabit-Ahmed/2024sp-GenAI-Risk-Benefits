---
layout: post
title: Domain Centered FMs 
lecture: S0-Intro
lectureVersion: next
extraContent: 
notes: team-2
video: team-2
tags:
- 1Basic
---

In this session, our readings cover: 

## Required Readings: 

### BloombergGPT: A Large Language Model for Finance
  https://arxiv.org/abs/2303.17564
  The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.
  
## More Readings: 

### Large language models generate functional protein sequences across diverse families
  https://pubmed.ncbi.nlm.nih.gov/36702895/


### FunSearch: Making new discoveries in mathematical sciences using Large Language Models
  https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/

### Transforming the future of music creation
  https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/



### Large Language Models in Law: A Survey
  https://arxiv.org/abs/2312.03718
  The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs, but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementation presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges. 


### Visual Instruction Tuning
Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee
Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. In this paper, we present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general-purpose visual and language understanding.Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.



### Segment Anything
  https://arxiv.org/abs/2304.02643
  We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at this https URL to foster research into foundation models for computer vision.


### ConvNets Match Vision Transformers at Scale 

# In this session, our blog covers: 
## Large Language Models for Software Engineering: A Systematic Literature Review

### 1 &nbsp; &nbsp; Overview
#### 1.1 &nbsp; Software Engineering
1. SE is a discipline focused on the development, implementation, and maintenance of software systems.
2. The utilization of LLMs in SE emerges from the perspective where numerous SE challenges can be effectively reframed into data, code, or text analysis tasks.
    
#### 1.2 &nbsp; Main Contributions
1. It covers 229 papers published between 2017 and 2023.
2. It summarizes usage and trends of different LLM categories within the SE domain.
3. It describes the data processing stages.
4. It discusses optimizers and evaluationg metrics used.
5. It analyzes key applications of LLMs in SE encompassing a diverse range of 55 specific SE tasks, grouped into six core SE activities.
6. It presents key challenges and potential research directions.

### 2 &nbsp; &nbsp; What LLMs have been employed?
#### 2.1 &nbsp; Models Distribution
1. There are more than 50 different LLMs used for SE tasks in the papers collected.
2. They are grouped into 3 categories based on their underlying architecture, i.e., encoder-only, encoder-decoder, and decoder-only LLMs.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE1.png" width="100%" height="100%">
1. __Encoder-only models__: Bert has been referenced in 41 of the papers, and its variants are also widely employed
2. __Encoder-decoder models__: there are fewer models and applications. CodeT5 is the most popular one.
3. __Decoder-only models__: Codex is used the most frequently.
4. Models that are specialized for code-related tasks are the most popular, because these models have shown efficacy in tasks requiring a nuanced understanding of the entire code snippet, which is very important in software engineering. 

#### 2.2 &nbsp; Trends Analysis
1. __Evolution of LLM architectures in 2021__: We see the emergence of decoder-only and encoder-decoder models in 2021.
2. __Diversity of LLM architectures in 2022__: 2022 experienced a significant increase in diversity, with more varied LLM architectures finding representation.
3. __Dominance of the decoder-only architecture in 2023__: 2023 signaled a strong shift towards decoder-only LLMs.
4. We see an increasing number of studies utilizing LLMs for software engineering. 
5. There is a shift in focus and resources toward exploring and harnessing the decoder-only architecture as the primary approach.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE2.png" width="100%" height="100%">

### 3 &nbsp; &nbsp; What types of SE datasets have been used in existing LLM4SE studies?
1. There are 5 categories based on data types: code-based, text-based, graph-based, software repository-based, and combined data types.
2. Most of the studies used text-based datasets, accounting for a total of 104.
3. Prompts dataset is the most common among all the text-based datasets, as prompt engineering is largely utilized.
4. Source code is the most abundant data type in code-based datasets, since source codes serve as the foundation of any software project.
5. There is a noticeable scarcity of graph-based datasets. Exploring graph-based datasets could be important for addressing complex code scenarios since graphs can better capture the structural relationships and dependencies in code. 
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE3.png" width="100%" height="100%">

### 4 &nbsp; &nbsp; What techniques are used to optimize and evaluate LLM4SE?
1. Fine-tuning emerges as the most widely used optimization algorithm in LLM studies, appearing in 87 research works, which actually signifies the dominance of fine-tuning in adapting pre-trained models to specific downstream tasks.
2. Among the learning rate optimization algorithms, Adam stands out with 25 occurrences in the studies. It is an adaptive optimization algorithm that combines adaptive learning rates with momentum, facilitating faster convergence and reducing the risk of getting stuck in local minima during training.
3. Prompt engineering has shown to be particularly advantageous in providing task-relevant knowledge and enhancing LLMs’ versatility and efficacy across different code intelligence tasks.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE4.png" width="100%" height="100%">

### 5 &nbsp; &nbsp; What SE tasks have been efficiently addressed by LLMs?
1. Based on the six phases of the Software Development Life Cycle (SDLC), the tasks are grouped into requirements engineering, software design, software development, software quality assurance, software maintenance, and software management.
2. The highest number of studies is observed in software development, which underscores the primary focus on utilizing LLMs to enhance coding and development processes. 
3. Software maintenance tasks account for about 24.89% of the research share, highlighting the significance of LLMs in aiding software updates and improvements. 
4. Based on the types of problems, the studies are classified into generation, classification, recommendation, and regression.
5. The majority of studies, about 64.34%, center around generation tasks, showing the significance of LLMs in producing code or text. 
6. Following this, around 24.48% of studies fall under classification tasks, which indicates the relevance of LLMs in categorizing software elements.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE5.png" width="100%" height="100%">


## Large Language Models in Law: A Survey

### 1 &nbsp; &nbsp; Overview
The following figure gives an overview of the survey.

<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p5/Figure1.png" width="100%" height="100%">

### 2 &nbsp; &nbsp; Contributions

Main contributions of this survey:
* The first comprehensive review article on legal LLMs
* Demonstrates use of legal LLMs
* Provides the latest research on legal LLMs
* Summarizes the key challenges and future directions of legal LLMs


### 3 &nbsp; &nbsp; Evolution of Judicial Technology
#### 3.1 &nbsp; Characteristics of Traditional Judicial System

When looking at the traditional judicial system that has been in use since before AI was a thing, we see a number of characteristics:

* Reliance on human decision-making
* Precedent-based
* Flexibility--the law and how it applies to a case depends on context of that particular case
* Time and resource-consuming

#### 3.1 &nbsp; Characteristics of AI in Legal Judgement

In order to effectively use AI in legal judgement, it is imperative to have a large amount of legal big data. However, examining the nature of the legal data that is available shows a number of characteristics that make the task difficult. Some legal big data characteristics:

* Unstructured
* Multilingual and multicultural
* Covers vast scale and complexities
* Timeliness
  * Must be regularly updated
* Data multi-sourcing
  * Comes from a variety of different sources
* Privacy and security concerns
  * May contain sensitive information, which must be removed before use

The following figure shows the main characteristics of LLMs in Judiciary:

<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p5/Figure3.png" width="100%" height="100%">

Some important use cases include:
* Language Understanding
  * LLMs can analyze legal documents and extract information from language
* Content generation
  * LLMs can automatically generate legal documents based on information given
* Speech-to-text conversion
* Give legal advice
  * LLMs can answer basic questions users may have about the law
* Matching optimal solutions for cases
  * AI can extract key features of the case and try to recommend an optimal solution for the case
* Case logic reasoning
* Improve judicial efficiency

### 4 &nbsp; &nbsp; Recent Applications

The following are ten popular legal LLMs that are examined by the survey. They are fine-tuned, mainly on question-answer legal data. 
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p5/Table1.png" width="100%" height="100%">

In August 2023, several institutions and universities developed a comprehensive evaluation system for legal AI systems. The evaluation system combines subjective and objective measures. There are four primary indicators: 

* Functional Indicators
* Performance Indicators
* Safety Indicators
* Quality Indicators 

There are also further subindicators for each category, which can be seen in the following figure:
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p5/Figure4.png" width="100%" height="100%">

### 5 &nbsp; &nbsp; Challenges
#### 5.1 &nbsp; Defects in Datasets

Legal LLMs still face a variety of challenges when it comes to widespread and accurate use. Some important challenges to consider are:

1) Inadequate Data Aquisition
* Insufficient sources of judicial data and documents
* Insufficient sharing of legal data
* Non-standard legal documents

2) Inaccurate Interpretation of Legal Concepts
* Current AI systems have some recognition deficiencies when it comes to legal concepts

3) Dataset Characteristics
* Timeliness
  * Legal concepts evolve as time passes, which is not always reflected in law data
* Credibility
  * Due to variety of laws and large number of judicial documents, bias and inaccuracies can still exist in datasets
* Scalability
  * Current scale of datasets can still be somewhat limited


#### 5.2 &nbsp; Shortcomings in Algorithms

1) Interpretability
* Insufficient interpretability reduces people’s trust in the judicial application of AI

2) Ethics, bias, and fairness
* Algorithms may contain elements of inequality
* Insufficient security in algorithm outsourcing
* Reduced transparency of LLMs in law may lead to judicial unfairness
* Algorithmic Bias


#### 5.3 &nbsp; Challenges of Traditional Legal Industry

##### 5.3.1 Neglecting Judicial Independence

   &nbsp; a) In terms of legal enforcement: it includes
  * Interpreting Civil Law
  * Explaining uncertain concepts, and evaluating disputes

   &nbsp; b) In terms of fact-finding: use of discretion, subjective judgment,
  experiential

Legal LLMs lead to
a) Overly relying on AI
b) Form preconceived notions

**For Example**,
In assessing the compensation amount in civil litigation, judges can
comprehensively consider factors such as the extent of the victim’s financial
loss and the defendant’s ability to compensate.
In contrast, the algorithms of legal LLMs struggle to measure the extent of
loss

Legal LLMs can assist judges. However, it does not possess professional judicial experience and cannot independently make judgments in cases


##### 5.3.2 Impact on Judicial System

Legal LLMs have restrained the subjective initiative of judges and the
development of traditional trial systems as reflected in:

1) Court idleness:
* Restrict the subjective initiative of judges
* Diminish the solemnity of the legal process

2) Crisis in the hierarchy of trial: Legal AI systems will impact the judicial process in the hierarchical system.

**For example**,
Any party dissatisfied with any judgment of a lower court can
appeal to a higher court which with legal AI system remains same.



#### 5.4 &nbsp; Issues Arising from Specific Judicial Practice

##### 5.4.1 &nbsp; The lack of universality in applications
Legal LLMs often extract feature values from cases and search for similar
cases within existing multidimensional datasets to find the “optimal solution”
Legal regulations may vary across different countries or regions, leading to
inconsistent decision outcomes for the same case under different legal rules,
so, the “optimal solution” proposed by the large model may not apply to a
particular case.

##### 5.4.2 &nbsp;  The lack of subjective thinking, emotions, and experience
Legal LLMs lack autonomous thinking abilities and professional experience,
among other things.
Judicial decision making process is not merely a logical reasoning process on
a single layer but also involves moral, ethical, and practical considerations in
the legal system.


##### 5.4.3 &nbsp;  Contradiction with the presumption of innocence principle
Various systems are used which predicts probability of crime without those even occurring like COMPAS system for crime prediction and risk assessment, PredPol for iterative calculation of potential crime locations
and PRECOBS system in Germany is used for burglary prevention and violence crime prediction.
* Imbalance of prosecution and defense
* Unequal control over data
* Differences in the ability to analyze case data
* Issues of policy attention, investment imbalance, and unequal exploration
* Administrative Performance

<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p3/Crime_Coefficient.jpg" width="100%" height="100%">
Figure: Futuristic System that apprehends people based on their probability of
committing Crime.




#### 5.5 &nbsp; Ethical Views Impacting Human Society

##### 5.5.1 &nbsp;  Disregard for human subjectivity:
Human subjectivity is susceptible to algorithmic bullying.
##### 5.5.2 &nbsp;  Misleading user comments:
In testing certain LLMs, such as ChatGPT, AI has displayed behaviors such
as inducing users to divorce, making inappropriate comments, and even
encouraging users to disclose personal privacy or engage in illegal activities
##### 5.5.3 &nbsp;  Ethical value consistency:
There may be situations where AI misleads or harms human interests.
Team 2 Domain Centered FMs March 23, 2024


### 6 &nbsp; Future Directions

#### 6.1 &nbsp; Data and Infrastructure
* Obtaining more comprehensive legal big data
* Defining the boundaries of legal concepts and limiting the scope of application
* Data transparency
* Building a legal knowledge graph
* Optimizing the foundational infrastructure for model training [High-performance computing resources, Storage and data management, Model scaling and deployment etc.]

#### 6.2 &nbsp; Algorithm Level:
* Strategy adjustment and optimized algorithm
* Limiting algorithmic biases and “black box” operations the scope of application
* Promote limited algorithmic transparency

#### 6.3 &nbsp; Dealing with Traditional Judiciary
* Clarifying the positioning of large models
* Defining the thinking capability of LLMs
* Ensuring parties’ access to data
* Expanding and optimizing the consulting function of judicial large models

#### 6.4 &nbsp; Judicial Practice:
* Improve accountability mechanisms to prevent political interference
* Foster the development of interdisciplinary talents
* Collaboration and sharing of experiences

### 7 &nbsp; Conclusions
This paper synthesized various technologies and ideas regarding the opportunities,
challenges, and recommendations for the application of AI in the judicial field.
Team 2 Domain Centered FMs March 23, 2024

## &nbsp; REFERENCES
https://arxiv.org/abs/2308.10620
https://arxiv.org/abs/2312.03718
https://arxiv.org/abs/2306.15794
https://arxiv.org/abs/2402.06852
https://www.nature.com/articles/s41586-021-03819-2
https://www.nature.com/articles/s41587-023-02115-w
https://www.nature.com/articles/s41587-022-01618-2
https://www.nature.com/articles/s41587-024-02127-0
https://www.biorxiv.org/content/10.1101/2024.02.10.579791v2
https://www.biorxiv.org/content/10.1101/2024.02.25.581968v1
https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1
https://www.biorxiv.org/content/10.1101/2023.01.11.523679v1
https://www.biorxiv.org/content/10.1101/2024.02.27.582234v1
