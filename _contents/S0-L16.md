---
layout: post
title: Domain Centered FMs 
lecture: S0-Intro
lectureVersion: next
extraContent: 
notes: team-2
video: team-2
tags:
- 1Basic
---

In this session, our readings cover: 

## Required Readings: 

### BloombergGPT: A Large Language Model for Finance
  https://arxiv.org/abs/2303.17564
  The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.
  
## More Readings: 

### Large language models generate functional protein sequences across diverse families
  https://pubmed.ncbi.nlm.nih.gov/36702895/


### FunSearch: Making new discoveries in mathematical sciences using Large Language Models
  https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/

### Transforming the future of music creation
  https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/



### Large Language Models in Law: A Survey
  https://arxiv.org/abs/2312.03718
  The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs, but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementation presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges. 


### Visual Instruction Tuning
Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee
Instruction tuning large language models (LLMs) using machine-generated instruction-following data has improved zero-shot capabilities on new tasks, but the idea is less explored in the multimodal field. In this paper, we present the first attempt to use language-only GPT-4 to generate multimodal language-image instruction-following data. By instruction tuning on such generated data, we introduce LLaVA: Large Language and Vision Assistant, an end-to-end trained large multimodal model that connects a vision encoder and LLM for general-purpose visual and language understanding.Our early experiments show that LLaVA demonstrates impressive multimodel chat abilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen images/instructions, and yields a 85.1% relative score compared with GPT-4 on a synthetic multimodal instruction-following dataset. When fine-tuned on Science QA, the synergy of LLaVA and GPT-4 achieves a new state-of-the-art accuracy of 92.53%. We make GPT-4 generated visual instruction tuning data, our model and code base publicly available.



### Segment Anything
  https://arxiv.org/abs/2304.02643
  We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at this https URL to foster research into foundation models for computer vision.


### ConvNets Match Vision Transformers at Scale 

# In this session, our blog covers: 
## Large Language Models for Software Engineering: A Systematic Literature Review

### 1 &nbsp; &nbsp; Overview
#### 1.1 &nbsp; Software Engineering
1. SE is a discipline focused on the development, implementation, and maintenance of software systems.
2. The utilization of LLMs in SE emerges from the perspective where numerous SE challenges can be effectively reframed into data, code, or text analysis tasks.
    
#### 1.2 &nbsp; Main Contributions
1. It covers 229 papers published between 2017 and 2023.
2. It summarizes usage and trends of different LLM categories within the SE domain.
3. It describes the data processing stages.
4. It discusses optimizers and evaluationg metrics used.
5. It analyzes key applications of LLMs in SE encompassing a diverse range of 55 specific SE tasks, grouped into six core SE activities.
6. It presents key challenges and potential research directions.

### 2 &nbsp; &nbsp; What LLMs have been employed?
#### 2.1 &nbsp; Models Distribution
1. There are more than 50 different LLMs used for SE tasks in the papers collected.
2. They are grouped into 3 categories based on their underlying architecture, i.e., encoder-only, encoder-decoder, and decoder-only LLMs.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE1.png" width="100%" height="100%">
1. __Encoder-only models__: Bert has been referenced in 41 of the papers, and its variants are also widely employed
2. __Encoder-decoder models__: there are fewer models and applications. CodeT5 is the most popular one.
3. __Decoder-only models__: Codex is used the most frequently.
4. Models that are specialized for code-related tasks are the most popular, because these models have shown efficacy in tasks requiring a nuanced understanding of the entire code snippet, which is very important in software engineering. 

#### 2.2 &nbsp; Trends Analysis
1. __Evolution of LLM architectures in 2021__: We see the emergence of decoder-only and encoder-decoder models in 2021.
2. __Diversity of LLM architectures in 2022__: 2022 experienced a significant increase in diversity, with more varied LLM architectures finding representation.
3. __Dominance of the decoder-only architecture in 2023__: 2023 signaled a strong shift towards decoder-only LLMs.
4. We see an increasing number of studies utilizing LLMs for software engineering. 
5. There is a shift in focus and resources toward exploring and harnessing the decoder-only architecture as the primary approach.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE2.png" width="100%" height="100%">

### 3 &nbsp; &nbsp; What types of SE datasets have been used in existing LLM4SE studies?
1. There are 5 categories based on data types: code-based, text-based, graph-based, software repository-based, and combined data types.
2. Most of the studies used text-based datasets, accounting for a total of 104.
3. Prompts dataset is the most common among all the text-based datasets, as prompt engineering is largely utilized.
4. Source code is the most abundant data type in code-based datasets, since source codes serve as the foundation of any software project.
5. There is a noticeable scarcity of graph-based datasets. Exploring graph-based datasets could be important for addressing complex code scenarios since graphs can better capture the structural relationships and dependencies in code. 
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE3.png" width="100%" height="100%">

### 4 &nbsp; &nbsp; What techniques are used to optimize and evaluate LLM4SE?
1. Fine-tuning emerges as the most widely used optimization algorithm in LLM studies, appearing in 87 research works, which actually signifies the dominance of fine-tuning in adapting pre-trained models to specific downstream tasks.
2. Among the learning rate optimization algorithms, Adam stands out with 25 occurrences in the studies. It is an adaptive optimization algorithm that combines adaptive learning rates with momentum, facilitating faster convergence and reducing the risk of getting stuck in local minima during training.
3. Prompt engineering has shown to be particularly advantageous in providing task-relevant knowledge and enhancing LLMsâ€™ versatility and efficacy across different code intelligence tasks.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE4.png" width="100%" height="100%">

### 5 &nbsp; &nbsp; What SE tasks have been efficiently addressed by LLMs?
1. Based on the six phases of the Software Development Life Cycle (SDLC), the tasks are grouped into requirements engineering, software design, software development, software quality assurance, software maintenance, and software management.
2. The highest number of studies is observed in software development, which underscores the primary focus on utilizing LLMs to enhance coding and development processes. 
3. Software maintenance tasks account for about 24.89% of the research share, highlighting the significance of LLMs in aiding software updates and improvements. 
4. Based on the types of problems, the studies are classified into generation, classification, recommendation, and regression.
5. The majority of studies, about 64.34%, center around generation tasks, showing the significance of LLMs in producing code or text. 
6. Following this, around 24.48% of studies fall under classification tasks, which indicates the relevance of LLMs in categorizing software elements.
<img src="{{ site.baseurl }}/Lectures/S0-L16/images/p1/SE5.png" width="100%" height="100%">
